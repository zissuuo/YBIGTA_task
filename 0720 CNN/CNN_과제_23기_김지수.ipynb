{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JZxvpsbK_KPA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAX7zz4Q7TW",
        "outputId": "1d1f459b-a83b-49c6-8b81-0a9186dc3e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IMrkSUyKQuaC"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "# Custom IPython progress bar for training\n",
        "class ProgressMonitor(object):\n",
        "\n",
        "    tmpl = \"\"\"\n",
        "        <table style=\"width: 100%;\">\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style=\"width: 30%;\">\n",
        "                     <b>Loss: {loss:0.4f}</b> &nbsp&nbsp&nbsp {value} / {length}\n",
        "                    </td>\n",
        "                    <td style=\"width: 70%;\">\n",
        "                        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0), display_id=True)\n",
        "\n",
        "    def html(self, count, loss):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
        "\n",
        "    def update(self, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vZgdPtMKB2kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e702ea-c591-4b82-9ad2-f07f5a649b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13000451.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = T.Compose( [T.RandomCrop(32, padding=4), T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "transform_test = T.Compose( [T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train )\n",
        "test_set = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test )\n",
        "\n",
        "classes = train_set.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmtRUX2Chc-",
        "outputId": "e67d8992-1880-47df-a4f6-7c696038d596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_set.data.shape)\n",
        "print(test_set.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0LjBgQWTAQBi"
      },
      "outputs": [],
      "source": [
        "# 과제 1- SimpleCNN의 오류를 없애라!\n",
        "# Hint- matrix의 size를 주의! maxpooling은 size를 1/2배한다. filter의 size도 중요\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "\n",
        "\n",
        "            #### 입력 이미지 크기 32x32x3\n",
        "\n",
        "            #32 * 32 * 3이므로 kernel size 3으로 수정\n",
        "\n",
        "            nn.Conv2d( in_channels=3, out_channels=64, kernel_size=3, padding=1 ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d( in_channels=64, out_channels=64, kernel_size=3, padding=1 ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d( in_channels=64, out_channels=128, kernel_size=3, padding=1 ),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "\n",
        "            ## maxpool 과정을 두번 거쳤으므로, 32 -> 16 -> 8이 되어, 4 * 4를 8 * 8로 수정해주어야 한다.\n",
        "            nn.Linear( 128 * 8 * 8, 500),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(500, 10),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_layers(x)\n",
        "\n",
        "        x = x.view( x.size(0), -1 ) # flatten\n",
        "\n",
        "        x = self.fc_layers(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-lKWDBrDqNNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f753b492-7e00-4c22-ac33-eb67012c2381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 10])\n"
          ]
        }
      ],
      "source": [
        "# 모델 테스트\n",
        "# 텐서의 사이즈가 (7, 10)이 나오면 성공\n",
        "# 현재는 오류가 뜨는 상황! matrix size를 잘 맞춰서 이 코드가 정상적으로 구동되면 성공입니다.\n",
        "\n",
        "temp = SimpleCNN()\n",
        "output = torch.randn( 7, 3, 32, 32)\n",
        "\n",
        "print( temp(output).size() )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습 2- Resnet 구현(선택)\n",
        "# Hint- layer를 지나간 뒤 input을 더해주어야 한다, stride말고 maxpool로 size 줄여도 괜찮습니다.\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "VqA6Q2pBBDyd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet 모델 테스트\n",
        "# 텐서의 사이즈가 (7, 10)이 나오면 성공\n",
        "\n",
        "temp = Resnet()\n",
        "output = torch.randn( 7, 3, 32, 32)\n",
        "\n",
        "print( temp(output).size() )\n"
      ],
      "metadata": {
        "id": "gMYDgEURCsIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2bfef7-2fa5-4436-ded0-514a344204a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FtKz3gmF_NTT"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 # 배치 사이즈\n",
        "learning_rate = 0.01 # 학습률\n",
        "num_epochs = 30 # 에폭 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XqBcfSB9QQbW"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z2Fe9zzeQzRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284ed65a-01bb-4a5f-d908-298fd916d037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=8192, out_features=500, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 원하는 모델을 돌려보세요\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JcuWxEnnRfGX"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer 선정\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SHkcPL-RRmEA"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "\n",
        "def train(optimizer, model, num_epochs=10, first_epoch=1):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
        "        print('Epoch', epoch)\n",
        "\n",
        "        # train phase\n",
        "        model.train()\n",
        "\n",
        "        # create a progress bar\n",
        "        progress = ProgressMonitor(length=len(train_set))\n",
        "\n",
        "        # keep track of predictions\n",
        "        correct_train = 0\n",
        "\n",
        "        batch_losses = []\n",
        "\n",
        "        for batch, targets in train_loader:\n",
        "\n",
        "            # Move the training data to the GPU\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # clear previous gradient computation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward propagation\n",
        "            outputs = model(batch)\n",
        "\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # backpropagate to compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            # accumulate correct count\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_train += torch.sum(preds == targets.data)\n",
        "\n",
        "            # update progress bar\n",
        "            progress.update(batch.shape[0], mean(batch_losses) )\n",
        "\n",
        "\n",
        "        train_losses.append( mean(batch_losses))\n",
        "\n",
        "\n",
        "        # test phase\n",
        "        model.eval()\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        correct_test = 0\n",
        "\n",
        "        # We don't need gradients for test, so wrap in\n",
        "        # no_grad to save memory\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch, targets in test_loader:\n",
        "\n",
        "                # Move the training batch to the GPU\n",
        "                batch = batch.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # forward propagation\n",
        "                outputs = model(batch)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # save predictions\n",
        "                y_pred.extend( outputs.argmax(dim=1).cpu().numpy() )\n",
        "\n",
        "                # accumulate correct count\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_test += torch.sum(preds == targets.data)\n",
        "\n",
        "\n",
        "        # Calculate accuracy\n",
        "        train_acc = correct_train.item() / train_set.data.shape[0]\n",
        "        test_acc = correct_test.item() / test_set.data.shape[0]\n",
        "\n",
        "        print('Training accuracy: {:.2f}%'.format(float(train_acc) * 100))\n",
        "        print('Test accuracy: {:.2f}%\\n'.format(float(test_acc) * 100))\n",
        "\n",
        "\n",
        "    return train_losses, test_losses, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPgk2q20Rq6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "outputId": "0f77863a-eeef-4e77-946e-1e8b96c5deec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <table style=\"width: 100%;\">\n",
              "            <tbody>\n",
              "                <tr>\n",
              "                    <td style=\"width: 30%;\">\n",
              "                     <b>Loss: 3.8535</b> &nbsp&nbsp&nbsp 43392 / 50000\n",
              "                    </td>\n",
              "                    <td style=\"width: 70%;\">\n",
              "                        <progress value='43392' max='50000', style='width: 100%'>43392</progress>\n",
              "                    </td>\n",
              "                </tr>\n",
              "            </tbody>\n",
              "        </table>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title\n",
        "train_losses, test_losses, y_pred = train(optimizer, model, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기까지 진행하고! ipynb 파일 제출해주세요."
      ],
      "metadata": {
        "id": "FBy1PpdRiK7b"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}